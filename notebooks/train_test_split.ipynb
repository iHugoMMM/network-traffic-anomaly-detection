{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the feature-engineered data\n",
    "file_path = '../data/processed/feature_engineered_30min.csv'\n",
    "df = pd.read_csv(file_path, index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create empty DataFrames with float64 dtype to properly handle NaN values\n",
    "train_df = df.astype('float64').copy()\n",
    "train_df[:] = np.nan\n",
    "\n",
    "test_df = df.astype('float64').copy()\n",
    "test_df[:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. For each column, compute local min_date and max_date, then split 80%/20%\n",
    "for col in df.columns:\n",
    "    # local min/max valid dates for this column\n",
    "    min_date = df[col].first_valid_index()\n",
    "    max_date = df[col].last_valid_index()\n",
    "\n",
    "    # If the column is entirely NaN or empty\n",
    "    if min_date is None or max_date is None or min_date == max_date:\n",
    "        continue  # skip this column\n",
    "\n",
    "    # Calculate the total time span\n",
    "    total_span = max_date - min_date\n",
    "    # 80% cutoff\n",
    "    cutoff_date = min_date + 0.8 * total_span\n",
    "\n",
    "    # TRAIN portion: from min_date to cutoff_date\n",
    "    train_mask = (df.index >= min_date) & (df.index <= cutoff_date)\n",
    "    # TEST portion: from cutoff_date to max_date\n",
    "    test_mask = (df.index > cutoff_date) & (df.index <= max_date)\n",
    "\n",
    "    # Assign values to train_df and test_df\n",
    "    train_df.loc[train_mask, col] = df.loc[train_mask, col]\n",
    "    test_df.loc[test_mask, col] = df.loc[test_mask, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Optional: drop rows that are entirely NaN (if you prefer a smaller DataFrame)\n",
    "train_df.dropna(axis=0, how='all', inplace=True)\n",
    "test_df.dropna(axis=0, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local train/test splits saved to data/processed/\n"
     ]
    }
   ],
   "source": [
    "# 5. Save to disk\n",
    "train_df.to_csv('../data/processed/train_local_80pct.csv')\n",
    "test_df.to_csv('../data/processed/test_local_20pct.csv')\n",
    "\n",
    "print(\"Local train/test splits saved to data/processed/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load train and test\n",
    "train_df = pd.read_csv('../data/processed/train_local_80pct.csv', index_col=0, parse_dates=True)\n",
    "test_df = pd.read_csv('../data/processed/test_local_20pct.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "# 2) Select numeric columns & fill NaNs\n",
    "train_data = train_df.select_dtypes(include='number').fillna(0)\n",
    "test_data = test_df.select_dtypes(include='number').fillna(0)\n",
    "\n",
    "# 3) Scale\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_data)\n",
    "X_test = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof = LocalOutlierFactor(\n",
    "    n_neighbors=20,      # how many neighbors to consider\n",
    "    contamination=0.05,  # fraction of outliers to expect\n",
    "    novelty=True         # IMPORTANT: allows separate train/test usage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Fit on the training data\n",
    "lof.fit(X_train)\n",
    "\n",
    "# 2) Predict on the test data\n",
    "#   +1 = normal, -1 = anomaly\n",
    "y_test_pred = lof.predict(X_test)\n",
    "\n",
    "# 3) LOF scores: bigger = more normal, smaller = more outlier\n",
    "scores_test = lof.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOF flagged 14026 anomalies out of 14026 test points.\n"
     ]
    }
   ],
   "source": [
    "results_df = test_df.copy()\n",
    "results_df['lof_label'] = y_test_pred\n",
    "results_df['lof_score'] = scores_test\n",
    "\n",
    "# Filter anomalies\n",
    "anomalies = results_df[results_df['lof_label'] == -1]\n",
    "print(f\"LOF flagged {len(anomalies)} anomalies out of {len(results_df)} test points.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1) Load train and test\n",
    "train_df = pd.read_csv('../data/processed/train_local_80pct.csv', index_col=0, parse_dates=True)\n",
    "test_df = pd.read_csv('../data/processed/test_local_20pct.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "# 2) Select numeric columns & fill NaNs\n",
    "train_data = train_df.select_dtypes(include='number').fillna(0)\n",
    "test_data = test_df.select_dtypes(include='number').fillna(0)\n",
    "\n",
    "# 3) Scale\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_data)\n",
    "X_test = scaler.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "oc_svm = OneClassSVM(\n",
    "    kernel='rbf',\n",
    "    gamma='auto',   # or pick a numeric value, e.g., 0.001\n",
    "    nu=0.05         # fraction of outliers you expect\n",
    ")\n",
    "\n",
    "oc_svm.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = oc_svm.predict(X_test)  # +1 = normal, -1 = anomaly\n",
    "scores_test = oc_svm.decision_function(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_df.copy()\n",
    "results_df['svm_label'] = y_test_pred\n",
    "results_df['svm_score'] = scores_test\n",
    "\n",
    "anomalies = results_df[results_df['svm_label'] == -1]\n",
    "print(f\"One-Class SVM flagged {len(anomalies)} anomalies out of {len(results_df)} test points.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_anomaly_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
